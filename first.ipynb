{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv3f62XyyAqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "41878e4b-4b78-4b60-e4b2-5ba8af92facb"
      },
      "source": [
        "# Training data\n",
        "!wget --header=\"Host: ivc.ischool.utexas.edu\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://vizwiz.org/tasks-and-datasets/image-captioning/\" \"https://ivc.ischool.utexas.edu/VizWiz_final/images/train.zip\" -c -O 'train.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 06:32:01--  https://ivc.ischool.utexas.edu/VizWiz_final/images/train.zip\n",
            "Resolving ivc.ischool.utexas.edu (ivc.ischool.utexas.edu)... 146.6.168.124\n",
            "Connecting to ivc.ischool.utexas.edu (ivc.ischool.utexas.edu)|146.6.168.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11298421598 (11G) [application/zip]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip            23%[===>                ]   2.50G  73.3MB/s    eta 1m 52s ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8sze7k5yar7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation data\n",
        "wget --header=\"Host: ivc.ischool.utexas.edu\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://vizwiz.org/tasks-and-datasets/image-captioning/\" \"https://ivc.ischool.utexas.edu/VizWiz_final/images/val.zip\" -c -O 'val.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvAgj4J9yN-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ed522dcb-53ba-4cf5-c745-da60f135fb13"
      },
      "source": [
        "# annotations\n",
        "!wget --header=\"Host: ivc.ischool.utexas.edu\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://vizwiz.org/tasks-and-datasets/image-captioning/\" \"https://ivc.ischool.utexas.edu/VizWiz_final/images/val.zip\" -c -O 'val.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 06:32:39--  https://ivc.ischool.utexas.edu/VizWiz_final/images/val.zip\n",
            "Resolving ivc.ischool.utexas.edu (ivc.ischool.utexas.edu)... 146.6.168.124\n",
            "Connecting to ivc.ischool.utexas.edu (ivc.ischool.utexas.edu)|146.6.168.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3488913457 (3.2G) [application/zip]\n",
            "Saving to: ‘val.zip’\n",
            "\n",
            "val.zip             100%[===================>]   3.25G  73.0MB/s    in 45s     \n",
            "\n",
            "2020-04-30 06:33:24 (73.8 MB/s) - ‘val.zip’ saved [3488913457/3488913457]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wq7Z9rayU4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__author__ = 'nilavra'\n",
        "__version__ = '1.0'\n",
        "# Interface for accessing the VizWiz dataset.\n",
        "\n",
        "# The codebase is adapted from Microsoft COCO Python API (http://cocodataset.org)\n",
        "# https://github.com/cocodataset/cocoapi\n",
        "\n",
        "# VizWiz is an image dataset originating from people who are blind, which is\n",
        "# designed for Visual Question Answering, caption generation, and a host of\n",
        "# other tasks. The VizWiz API assists in loading, parsing and visualizing the\n",
        "# annotations in VizWiz. # Please visit http://vizwiz.org for more information\n",
        "# on VizWiz, including # for the data, paper, and tutorials. The exact format\n",
        "# of the annotations # is also described on the VizWiz website. In addition\n",
        "# to this API, please download both the VizWiz images and annotations in order\n",
        "# to run the demo.\n",
        "\n",
        "# The following API functions are defined:\n",
        "#  VizWiz     - VizWiz api class that loads VizWiz annotation file and prepare data structures.\n",
        "#  getImgIds  - Get img ids that satisfy given filter conditions.\n",
        "#  loadImgs   - Load imgs with the specified ids.\n",
        "#  getAnnIds  - Get ann ids that satisfy given filter conditions.\n",
        "#  loadAnns   - Load anns with the specified ids.\n",
        "#  showAnns   - Display the specified annotations.\n",
        "#  loadRes    - Load algorithm results and create API for accessing them.\n",
        "#  download   - Download COCO images from mscoco.org server.\n",
        "\n",
        "# The following API functions are also available:\n",
        "#  getCatIds  - Get cat ids that satisfy given filter conditions.\n",
        "#  loadCats   - Load cats with the specified ids.\n",
        "\n",
        "# The following API functions were present in the original COCO API, but they\n",
        "# have not been implemented here\n",
        "#  decodeMask - Decode binary mask M encoded via run-length encoding.\n",
        "#  encodeMask - Encode binary mask M using run-length encoding.\n",
        "#  annToMask  - Convert segmentation in an annotation to binary mask.\n",
        "\n",
        "# Throughout the API \"ann\"=annotation, \"img\"=image, and \"cat\"=category,.\n",
        "\n",
        "# VizWiz API Version 1.0\n",
        "# Data, paper, and tutorials available at:  http://vizwiz.org\n",
        "# Code written by Nilavra Bhattacharya, 2019.\n",
        "# Licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0)\n",
        "# https://creativecommons.org/licenses/by/4.0\n",
        "\n",
        "\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import PatchCollection\n",
        "from matplotlib.patches import Polygon\n",
        "import numpy as np\n",
        "import copy\n",
        "import itertools\n",
        "#from . import mask as maskUtils\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import sys\n",
        "PYTHON_VERSION = sys.version_info[0]\n",
        "if PYTHON_VERSION == 2:\n",
        "    from urllib import urlretrieve\n",
        "elif PYTHON_VERSION == 3:\n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "\n",
        "def _isArrayLike(obj):\n",
        "    return hasattr(obj, '__iter__') and hasattr(obj, '__len__')\n",
        "\n",
        "\n",
        "class VizWiz:\n",
        "    def __init__(self, annotation_file=None, ignore_rejected=True, ignore_precanned=True):\n",
        "        \"\"\"\n",
        "        Constructor of VizWiz helper class for reading and visualizing annotations.\n",
        "        :param annotation_file (str): location of annotation file\n",
        "        :param image_folder (str): location to the folder that hosts images.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # load dataset\n",
        "        self.dataset,self.anns,self.cats,self.imgs = dict(),dict(),dict(),dict()\n",
        "        self.imgToAnns, self.catToImgs = defaultdict(list), defaultdict(list)\n",
        "        if not annotation_file == None:\n",
        "            print('loading annotations into memory...')\n",
        "            tic = time.time()\n",
        "            dataset = json.load(open(annotation_file, 'r'))\n",
        "            assert type(dataset) == dict, 'annotation file format {} not supported'.format(type(dataset))\n",
        "            self.dataset = {}\n",
        "            for key, value in dataset.items():\n",
        "                if key != 'annotations':\n",
        "                    self.dataset[key] = value\n",
        "            self.dataset['annotations'] = []\n",
        "            for annotation in dataset['annotations']:\n",
        "                if (ignore_rejected and annotation['is_rejected']) \\\n",
        "                    or (ignore_precanned and annotation['is_precanned']):\n",
        "                    continue\n",
        "                else:\n",
        "                    self.dataset['annotations'].append(annotation)\n",
        "            \n",
        "            print('Done (t={:0.2f}s)'.format(time.time()- tic))\n",
        "            #self.dataset = dataset\n",
        "            self.createIndex()\n",
        "\n",
        "    def createIndex(self):\n",
        "        # create index\n",
        "        print('creating index...')\n",
        "        anns, cats, imgs = {}, {}, {}\n",
        "        imgToAnns,catToImgs = defaultdict(list),defaultdict(list)\n",
        "        if 'annotations' in self.dataset:\n",
        "            for ann in self.dataset['annotations']:\n",
        "                imgToAnns[ann['image_id']].append(ann)\n",
        "                anns[ann['id']] = ann\n",
        "\n",
        "        if 'images' in self.dataset:\n",
        "            for img in self.dataset['images']:\n",
        "                imgs[img['id']] = img\n",
        "\n",
        "        if 'categories' in self.dataset:\n",
        "            for cat in self.dataset['categories']:\n",
        "                cats[cat['id']] = cat\n",
        "\n",
        "        if 'annotations' in self.dataset and 'categories' in self.dataset:\n",
        "            for ann in self.dataset['annotations']:\n",
        "                catToImgs[ann['category_id']].append(ann['image_id'])\n",
        "\n",
        "        # create class members\n",
        "        self.anns = anns\n",
        "        self.imgToAnns = imgToAnns\n",
        "        self.catToImgs = catToImgs\n",
        "        self.imgs = imgs\n",
        "        self.cats = cats\n",
        "\n",
        "        print('index created! imgs = %d, anns = %d'\n",
        "              % (len(self.imgs), len(self.anns))\n",
        "        )\n",
        "\n",
        "    def info(self):\n",
        "        \"\"\"\n",
        "        Print information about the annotation file.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        for key, value in self.dataset['info'].items():\n",
        "            print('{}: {}'.format(key, value))\n",
        "\n",
        "    def getAnnIds(self, imgIds=[], catIds=[], areaRng=[], iscrowd=None):\n",
        "        \"\"\"\n",
        "        Get ann ids that satisfy given filter conditions. default skips that filter\n",
        "        :param imgIds  (int array)     : get anns for given imgs\n",
        "               catIds  (int array)     : get anns for given cats\n",
        "               areaRng (float array)   : get anns for given area range (e.g. [0 inf])\n",
        "               iscrowd (boolean)       : get anns for given crowd label (False or True)\n",
        "        :return: ids (int array)       : integer array of ann ids\n",
        "        \"\"\"\n",
        "        imgIds = imgIds if _isArrayLike(imgIds) else [imgIds]\n",
        "        catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
        "\n",
        "        if len(imgIds) == len(catIds) == len(areaRng) == 0:\n",
        "            anns = self.dataset['annotations']\n",
        "        else:\n",
        "            if not len(imgIds) == 0:\n",
        "                lists = [self.imgToAnns[imgId] for imgId in imgIds if imgId in self.imgToAnns]\n",
        "                anns = list(itertools.chain.from_iterable(lists))\n",
        "            else:\n",
        "                anns = self.dataset['annotations']\n",
        "            anns = anns if len(catIds)  == 0 else [ann for ann in anns if ann['category_id'] in catIds]\n",
        "            anns = anns if len(areaRng) == 0 else [ann for ann in anns if ann['area'] > areaRng[0] and ann['area'] < areaRng[1]]\n",
        "        if not iscrowd == None:\n",
        "            ids = [ann['id'] for ann in anns if ann['iscrowd'] == iscrowd]\n",
        "        else:\n",
        "            ids = [ann['id'] for ann in anns]\n",
        "        return ids\n",
        "\n",
        "    def getCatIds(self, catNms=[], supNms=[], catIds=[]):\n",
        "        \"\"\"\n",
        "        filtering parameters. default skips that filter.\n",
        "        :param catNms (str array)  : get cats for given cat names\n",
        "        :param supNms (str array)  : get cats for given supercategory names\n",
        "        :param catIds (int array)  : get cats for given cat ids\n",
        "        :return: ids (int array)   : integer array of cat ids\n",
        "        \"\"\"\n",
        "        catNms = catNms if _isArrayLike(catNms) else [catNms]\n",
        "        supNms = supNms if _isArrayLike(supNms) else [supNms]\n",
        "        catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
        "\n",
        "        if len(catNms) == len(supNms) == len(catIds) == 0:\n",
        "            cats = self.dataset['categories']\n",
        "        else:\n",
        "            cats = self.dataset['categories']\n",
        "            cats = cats if len(catNms) == 0 else [cat for cat in cats if cat['name']          in catNms]\n",
        "            cats = cats if len(supNms) == 0 else [cat for cat in cats if cat['supercategory'] in supNms]\n",
        "            cats = cats if len(catIds) == 0 else [cat for cat in cats if cat['id']            in catIds]\n",
        "        ids = [cat['id'] for cat in cats]\n",
        "        return ids\n",
        "\n",
        "    def getImgIds(self, imgIds=[], catIds=[]):\n",
        "        '''\n",
        "        Get img ids that satisfy given filter conditions.\n",
        "        :param imgIds (int array) : get imgs for given ids\n",
        "        :param catIds (int array) : get imgs with all given cats\n",
        "        :return: ids (int array)  : integer array of img ids\n",
        "        '''\n",
        "        imgIds = imgIds if _isArrayLike(imgIds) else [imgIds]\n",
        "        catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
        "\n",
        "        if len(imgIds) == len(catIds) == 0:\n",
        "            ids = self.imgs.keys()\n",
        "        else:\n",
        "            ids = set(imgIds)\n",
        "            for i, catId in enumerate(catIds):\n",
        "                if i == 0 and len(ids) == 0:\n",
        "                    ids = set(self.catToImgs[catId])\n",
        "                else:\n",
        "                    ids &= set(self.catToImgs[catId])\n",
        "        return list(ids)\n",
        "\n",
        "    def loadAnns(self, ids=[]):\n",
        "        \"\"\"\n",
        "        Load anns with the specified ids.\n",
        "        :param ids (int array)       : integer ids specifying anns\n",
        "        :return: anns (object array) : loaded ann objects\n",
        "        \"\"\"\n",
        "        if _isArrayLike(ids):\n",
        "            return [self.anns[id] for id in ids]\n",
        "        elif type(ids) == int:\n",
        "            return [self.anns[ids]]\n",
        "\n",
        "    def loadCats(self, ids=[]):\n",
        "        \"\"\"\n",
        "        Load cats with the specified ids.\n",
        "        :param ids (int array)       : integer ids specifying cats\n",
        "        :return: cats (object array) : loaded cat objects\n",
        "        \"\"\"\n",
        "        if _isArrayLike(ids):\n",
        "            return [self.cats[id] for id in ids]\n",
        "        elif type(ids) == int:\n",
        "            return [self.cats[ids]]\n",
        "\n",
        "    def loadImgs(self, ids=[]):\n",
        "        \"\"\"\n",
        "        Load anns with the specified ids.\n",
        "        :param ids (int array)       : integer ids specifying img\n",
        "        :return: imgs (object array) : loaded img objects\n",
        "        \"\"\"\n",
        "        if _isArrayLike(ids):\n",
        "            return [self.imgs[id] for id in ids]\n",
        "        elif type(ids) == int:\n",
        "            return [self.imgs[ids]]\n",
        "\n",
        "    def showAnns(self, anns):\n",
        "        \"\"\"\n",
        "        Display the specified annotations.\n",
        "        :param anns (array of object): annotations to display\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        if len(anns) == 0:\n",
        "            return 0\n",
        "        if 'segmentation' in anns[0] or 'keypoints' in anns[0]:\n",
        "            datasetType = 'instances'\n",
        "        elif 'caption' in anns[0]:\n",
        "            datasetType = 'captions'\n",
        "        else:\n",
        "            raise Exception('datasetType not supported')\n",
        "\n",
        "        if datasetType == 'captions':\n",
        "            for ann in anns:\n",
        "                print(ann['caption'])\n",
        "\n",
        "        #####################################################\n",
        "        # implement other annotation types as needed below\n",
        "        #####################################################\n",
        "        \"\"\"\n",
        "        elif datasetType == 'instances':\n",
        "            \n",
        "            ax = plt.gca()\n",
        "            ax.set_autoscale_on(False)\n",
        "            polygons = []\n",
        "            color = []\n",
        "            for ann in anns:\n",
        "                c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
        "                if 'segmentation' in ann:\n",
        "                    if type(ann['segmentation']) == list:\n",
        "                        # polygon\n",
        "                        for seg in ann['segmentation']:\n",
        "                            poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
        "                            polygons.append(Polygon(poly))\n",
        "                            color.append(c)\n",
        "                    else:\n",
        "                        # mask\n",
        "                        t = self.imgs[ann['image_id']]\n",
        "                        if type(ann['segmentation']['counts']) == list:\n",
        "                            rle = maskUtils.frPyObjects([ann['segmentation']], t['height'], t['width'])\n",
        "                        else:\n",
        "                            rle = [ann['segmentation']]\n",
        "                        m = maskUtils.decode(rle)\n",
        "                        img = np.ones( (m.shape[0], m.shape[1], 3) )\n",
        "                        if ann['iscrowd'] == 1:\n",
        "                            color_mask = np.array([2.0,166.0,101.0])/255\n",
        "                        if ann['iscrowd'] == 0:\n",
        "                            color_mask = np.random.random((1, 3)).tolist()[0]\n",
        "                        for i in range(3):\n",
        "                            img[:,:,i] = color_mask[i]\n",
        "                        ax.imshow(np.dstack( (img, m*0.5) ))\n",
        "                if 'keypoints' in ann and type(ann['keypoints']) == list:\n",
        "                    # turn skeleton into zero-based index\n",
        "                    sks = np.array(self.loadCats(ann['category_id'])[0]['skeleton'])-1\n",
        "                    kp = np.array(ann['keypoints'])\n",
        "                    x = kp[0::3]\n",
        "                    y = kp[1::3]\n",
        "                    v = kp[2::3]\n",
        "                    for sk in sks:\n",
        "                        if np.all(v[sk]>0):\n",
        "                            plt.plot(x[sk],y[sk], linewidth=3, color=c)\n",
        "                    plt.plot(x[v>0], y[v>0],'o',markersize=8, markerfacecolor=c, markeredgecolor='k',markeredgewidth=2)\n",
        "                    plt.plot(x[v>1], y[v>1],'o',markersize=8, markerfacecolor=c, markeredgecolor=c, markeredgewidth=2)\n",
        "            p = PatchCollection(polygons, facecolor=color, linewidths=0, alpha=0.4)\n",
        "            ax.add_collection(p)\n",
        "            p = PatchCollection(polygons, facecolor='none', edgecolors=color, linewidths=2)\n",
        "            ax.add_collection(p)\n",
        "        \"\"\"\n",
        "\n",
        "    def loadRes(self, resFile):\n",
        "        \"\"\"\n",
        "        Load result file and return a result api object.\n",
        "        :param   resFile (str)     : file name of result file\n",
        "        :return: res (obj)         : result api object\n",
        "        \"\"\"\n",
        "        res = VizWiz()\n",
        "        res.dataset['images'] = [img for img in self.dataset['images']]\n",
        "\n",
        "        print('Loading and preparing results...')\n",
        "        tic = time.time()\n",
        "        if type(resFile) == str or type(resFile) == bytes:\n",
        "            anns = json.load(open(resFile))\n",
        "        elif type(resFile) == np.ndarray:\n",
        "            anns = self.loadNumpyAnnotations(resFile)\n",
        "        else:\n",
        "            anns = resFile\n",
        "        assert type(anns) == list, 'results in not an array of objects'\n",
        "        annsImgIds = [ann['image_id'] for ann in anns]\n",
        "        assert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n",
        "            'Results do not correspond to current VizWiz set'\n",
        "        if 'caption' in anns[0]:\n",
        "            imgIds = set([img['id'] for img in res.dataset['images']]) & set([ann['image_id'] for ann in anns])\n",
        "            res.dataset['images'] = [img for img in res.dataset['images'] if img['id'] in imgIds]\n",
        "            for id, ann in enumerate(anns):\n",
        "                ann['id'] = id+1\n",
        "\n",
        "        #####################################################\n",
        "        # implement other annotation types as needed below\n",
        "        #####################################################\n",
        "        \"\"\"\n",
        "        elif 'bbox' in anns[0] and not anns[0]['bbox'] == []:\n",
        "            res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
        "            for id, ann in enumerate(anns):\n",
        "                bb = ann['bbox']\n",
        "                x1, x2, y1, y2 = [bb[0], bb[0]+bb[2], bb[1], bb[1]+bb[3]]\n",
        "                if not 'segmentation' in ann:\n",
        "                    ann['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n",
        "                ann['area'] = bb[2]*bb[3]\n",
        "                ann['id'] = id+1\n",
        "                ann['iscrowd'] = 0\n",
        "        elif 'segmentation' in anns[0]:\n",
        "            res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
        "            for id, ann in enumerate(anns):\n",
        "                # now only support compressed RLE format as segmentation results\n",
        "                ann['area'] = maskUtils.area(ann['segmentation'])\n",
        "                if not 'bbox' in ann:\n",
        "                    ann['bbox'] = maskUtils.toBbox(ann['segmentation'])\n",
        "                ann['id'] = id+1\n",
        "                ann['iscrowd'] = 0\n",
        "        elif 'keypoints' in anns[0]:\n",
        "            res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
        "            for id, ann in enumerate(anns):\n",
        "                s = ann['keypoints']\n",
        "                x = s[0::3]\n",
        "                y = s[1::3]\n",
        "                x0,x1,y0,y1 = np.min(x), np.max(x), np.min(y), np.max(y)\n",
        "                ann['area'] = (x1-x0)*(y1-y0)\n",
        "                ann['id'] = id + 1\n",
        "                ann['bbox'] = [x0,y0,x1-x0,y1-y0]\n",
        "        \"\"\"\n",
        "\n",
        "        print('DONE (t={:0.2f}s)'.format(time.time()- tic))\n",
        "\n",
        "        res.dataset['annotations'] = anns\n",
        "        res.createIndex()\n",
        "        return res\n",
        "\n",
        "    def download(self, tarDir = None, imgIds = [] ):\n",
        "        '''\n",
        "        Download VizWiz images from vizwiz.org server.\n",
        "        :param tarDir (str): VizWiz results directory name\n",
        "               imgIds (list): images to be downloaded\n",
        "        :return:\n",
        "        '''\n",
        "        if tarDir is None:\n",
        "            print('Please specify target directory')\n",
        "            return -1\n",
        "        if len(imgIds) == 0:\n",
        "            imgs = self.imgs.values()\n",
        "        else:\n",
        "            imgs = self.loadImgs(imgIds)\n",
        "        N = len(imgs)\n",
        "        if not os.path.exists(tarDir):\n",
        "            os.makedirs(tarDir)\n",
        "        for i, img in enumerate(imgs):\n",
        "            tic = time.time()\n",
        "            fname = os.path.join(tarDir, img['file_name'])\n",
        "            if not os.path.exists(fname):\n",
        "                urlretrieve(img['vizwiz_url'], fname)\n",
        "            print('downloaded {}/{} images (t={:0.1f}s)'.format(i, N, time.time()- tic))\n",
        "\n",
        "    def loadNumpyAnnotations(self, data):\n",
        "        \"\"\"\n",
        "        Convert result data from a numpy array [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}\n",
        "        :param  data (numpy.ndarray)\n",
        "        :return: annotations (python nested list)\n",
        "        \"\"\"\n",
        "        print('Converting ndarray to lists...')\n",
        "        assert(type(data) == np.ndarray)\n",
        "        print(data.shape)\n",
        "        assert(data.shape[1] == 7)\n",
        "        N = data.shape[0]\n",
        "        ann = []\n",
        "        for i in range(N):\n",
        "            if i % 1000000 == 0:\n",
        "                print('{}/{}'.format(i,N))\n",
        "            ann += [{\n",
        "                'image_id'  : int(data[i, 0]),\n",
        "                'bbox'  : [ data[i, 1], data[i, 2], data[i, 3], data[i, 4] ],\n",
        "                'score' : data[i, 5],\n",
        "                'category_id': int(data[i, 6]),\n",
        "            }]\n",
        "        return ann\n",
        "\n",
        "    def annToRLE(self, ann):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        t = self.imgs[ann['image_id']]\n",
        "        h, w = t['height'], t['width']\n",
        "        segm = ann['segmentation']\n",
        "        if type(segm) == list:\n",
        "            # polygon -- a single object might consist of multiple parts\n",
        "            # we merge all parts into one mask rle code\n",
        "            rles = maskUtils.frPyObjects(segm, h, w)\n",
        "            rle = maskUtils.merge(rles)\n",
        "        elif type(segm['counts']) == list:\n",
        "            # uncompressed RLE\n",
        "            rle = maskUtils.frPyObjects(segm, h, w)\n",
        "        else:\n",
        "            # rle\n",
        "            rle = ann['segmentation']\n",
        "        return rle\n",
        "        \"\"\"\n",
        "\n",
        "    def annToMask(self, ann):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        rle = self.annToRLE(ann)\n",
        "        m = maskUtils.decode(rle)\n",
        "        return m\n",
        "        \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brxukFfZzbu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuvTDzMiznE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/val.zip') as z:\n",
        "  z.extractall()\n",
        "\n",
        "with ZipFile('/content/annotations.zip') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT7FDB2s0X2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bccaedd8-e1b7-4a8c-e435-1ea64a98ebf4"
      },
      "source": [
        "valid_ = VizWiz(annotation_file='/content/annotations/val.json')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.10s)\n",
            "creating index...\n",
            "index created! imgs = 7750, anns = 33145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWO2_LU0f4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fd3723f9-467e-4ea2-8667-18896cdfd1d2"
      },
      "source": [
        "valid_.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "description: This dataset contains crowdsourced captions of images from VizWiz datasets. This file contains the val partition.\n",
            "license: {'url': 'https://creativecommons.org/licenses/by/4.0/', 'name': 'Attribution 4.0 International (CC BY 4.0)'}\n",
            "url: https://vizwiz.org\n",
            "version: VizWiz-Captions 1.0\n",
            "year: 2019\n",
            "contributor: VizWiz-Captions Consortium\n",
            "date_created: 2019-12-23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMoAyBKh16Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_.anns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8tEKsUv4SPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ff524b8-fbcb-40c9-9238-2090c62bba61"
      },
      "source": [
        "len(valid_.anns), len(valid_.imgs), "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33145, 7750, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26bbW74i48qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "file = json.load(open('/content/annotations/val.json'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A2CIVCa57DE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5fec704-e198-4d0d-b74f-87db99e4eb91"
      },
      "source": [
        "len(file['annotations']), len(file['images'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38750, 7750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLn2FGO06ZSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetEncoder(nn.Module):\n",
        "  def __init_(self, outsize):\n",
        "    super(ResnetEncoder, self).__init__()\n",
        "    # pretrained resnet model\n",
        "    resnet = models.resnet50(pretrained = True)\n",
        "    # removing classifier linear layers\n",
        "    # as we require only the features of the images\n",
        "    self.resnet = nn.Sequential(*list(resnet.children())[:-2])\n",
        "    # for variable size input images -> fixed sized output\n",
        "    self.AvgPool = nn.AdaptiveAvgPool2d((outsize, outsize))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.resnet(x)\n",
        "    x = self.AvgPool(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5lesvlGDLLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "  def __init__(self, output_sz, hidden_sz):\n",
        "    super(AttnDecoder, self)._init__()\n",
        "    self.embedding = nn.Embedding()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNnsx_q4DLvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}